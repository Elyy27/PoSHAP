{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10126722,"sourceType":"datasetVersion","datasetId":6249247}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score,mean_absolute_error, mean_squared_error\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import GRU\n\nimport keras_tuner\nfrom kerastuner.tuners import RandomSearch\nfrom tensorflow.keras.callbacks import EarlyStopping, Callback\n\n!pip install shap\nimport shap\nimport pickle\nimport copy\n\nimport seaborn as sns; sns.set_theme()\nfrom matplotlib import rcParams\nimport matplotlib.pyplot as plt\nimport matplotlib as mlp\n\nimport lime\nimport lime.lime_tabular","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:17:30.229439Z","iopub.execute_input":"2024-12-12T15:17:30.229688Z","iopub.status.idle":"2024-12-12T15:17:57.525614Z","shell.execute_reply.started":"2024-12-12T15:17:30.229661Z","shell.execute_reply":"2024-12-12T15:17:57.524610Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/617929475.py:17: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n  from kerastuner.tuners import RandomSearch\n/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: shap in /opt/conda/lib/python3.10/site-packages (0.44.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from shap) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from shap) (1.14.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from shap) (1.2.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from shap) (2.2.3)\nRequirement already satisfied: tqdm>=4.27.0 in /opt/conda/lib/python3.10/site-packages (from shap) (4.66.4)\nRequirement already satisfied: packaging>20.9 in /opt/conda/lib/python3.10/site-packages (from shap) (21.3)\nRequirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.10/site-packages (from shap) (0.0.7)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from shap) (0.60.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from shap) (3.1.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>20.9->shap) (3.1.2)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->shap) (0.43.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->shap) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->shap) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->shap) (2024.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->shap) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->shap) (3.5.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"inp = pd.read_csv(\"/kaggle/input/ccs-position-data/CCS.csv\", header = 0, low_memory=False, sep=\",\")\ninp.index = range(len(inp))\ninp.head()\n\ninp = inp.groupby('Sequence', as_index=False).mean()\ninp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:08:54.609393Z","iopub.execute_input":"2024-12-07T13:08:54.609991Z","iopub.status.idle":"2024-12-07T13:08:54.717582Z","shell.execute_reply.started":"2024-12-07T13:08:54.609955Z","shell.execute_reply":"2024-12-07T13:08:54.716597Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Tạo list các axit amin để encoding\npeptides = inp['Sequence'].tolist()\npeptides.sort()\nvocab = set(''.join([str(i) for i in peptides]))\nvocab.add('END')\nvocab_list = list(vocab)\nvocab_list.sort()\n#vocab_list\n\n#Thêm END vào các peptides dài 8-9 có độ dài 10 \nchar_index = dict((vocab_list[i], i) for i in range(len(vocab_list)))\nX = []\nx_name = [str(i)[0:10] for i in peptides]\nfor i in x_name:\n    tmp = [char_index[j] for j in str(i)]\n    for k in range(0,10 - len(str(i))):\n        tmp.append(char_index[\"END\"])\n    X.append(tmp)\n#X\n\n#Tạo list chứa toàn bộ giá trị CCS\nY = []\nfor index, row in inp.iterrows():\n    my_list = [row.CCS]\n    Y.append(my_list)\n#all_int_list[0]\n\nX = np.asarray(X)\nY = np.asarray(Y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:46:42.319149Z","iopub.execute_input":"2024-12-07T08:46:42.319531Z","iopub.status.idle":"2024-12-07T08:46:45.221211Z","shell.execute_reply.started":"2024-12-07T08:46:42.319498Z","shell.execute_reply":"2024-12-07T08:46:45.220114Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Chia thành tập train, test, val\nx_train_all, x_test, y_train_all, y_test = train_test_split(X,Y, test_size=0.1, random_state=42)\nx_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, test_size=0.2, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.savetxt('CCS_x_test.txt', x_test)\nnp.savetxt('CCS_y_test.txt', y_test)\nnp.savetxt('CCS_x_train.txt', x_train)\nnp.savetxt('CCS_y_train.txt', y_train)\nnp.savetxt('CCS_x_val.txt', x_val)\nnp.savetxt('CCS_y_val.txt', y_val)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train = np.loadtxt('/kaggle/input/ccs-position-data/CCS_x_train.txt')\n\nx_test = np.loadtxt('/kaggle/input/ccs-position-data/CCS_x_test.txt')\n\ny_train = np.loadtxt('/kaggle/input/ccs-position-data/CCS_y_train.txt')\n\ny_test = np.loadtxt('/kaggle/input/ccs-position-data/CCS_y_test.txt')\n\nx_val = np.loadtxt('/kaggle/input/ccs-position-data/CCS_x_val.txt')\n\ny_val = np.loadtxt('/kaggle/input/ccs-position-data/CCS_y_val.txt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:17:57.527366Z","iopub.execute_input":"2024-12-12T15:17:57.527806Z","iopub.status.idle":"2024-12-12T15:17:57.807794Z","shell.execute_reply.started":"2024-12-12T15:17:57.527778Z","shell.execute_reply":"2024-12-12T15:17:57.807037Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"%%time\n\n#Model LSTM \nmodel = Sequential()\nmodel.add(Embedding(output_dim = 50, input_dim = 21, input_length = 10))\n\nmodel.add(LSTM(128,return_sequences=False, input_shape=(10,21)))\nmodel.add(Dropout(0.53))\n\nmodel.add(Dense(64))\nmodel.add(Dropout(0.09))\n\nmodel.add(Dense(1))\n\noptimizermodel = tf.keras.optimizers.Adam(0.001)\noptimizermodel.learning_rate.assign(0.005)\nmodel.compile(loss='mse', optimizer = optimizermodel, metrics=['mse'])\n\nhist = model.fit(x_train, y_train,\n                batch_size = 128,\n                epochs = 200,\n                validation_data = (x_val, y_val))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:32:01.052092Z","iopub.execute_input":"2024-12-12T15:32:01.052483Z","iopub.status.idle":"2024-12-12T15:36:19.028791Z","shell.execute_reply.started":"2024-12-12T15:32:01.052450Z","shell.execute_reply":"2024-12-12T15:36:19.027953Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/200\n","output_type":"stream"},{"name":"stderr","text":"Argument `input_length` is deprecated. Just remove it.\nDo not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 25949.0273 - mse: 25949.0273 - val_loss: 617.4554 - val_mse: 617.4554\nEpoch 2/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1922.5776 - mse: 1922.5776 - val_loss: 645.7042 - val_mse: 645.7042\nEpoch 3/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1875.4076 - mse: 1875.4076 - val_loss: 639.0408 - val_mse: 639.0408\nEpoch 4/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1862.2643 - mse: 1862.2643 - val_loss: 632.1873 - val_mse: 632.1873\nEpoch 5/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1846.8285 - mse: 1846.8285 - val_loss: 620.6031 - val_mse: 620.6031\nEpoch 6/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1811.8513 - mse: 1811.8513 - val_loss: 629.2465 - val_mse: 629.2465\nEpoch 7/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1788.1732 - mse: 1788.1732 - val_loss: 620.2533 - val_mse: 620.2533\nEpoch 8/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1751.6958 - mse: 1751.6958 - val_loss: 621.2853 - val_mse: 621.2853\nEpoch 9/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1724.5385 - mse: 1724.5385 - val_loss: 668.0835 - val_mse: 668.0835\nEpoch 10/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1667.6456 - mse: 1667.6456 - val_loss: 646.9749 - val_mse: 646.9749\nEpoch 11/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1566.4723 - mse: 1566.4723 - val_loss: 634.1969 - val_mse: 634.1969\nEpoch 12/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1457.8558 - mse: 1457.8558 - val_loss: 645.6743 - val_mse: 645.6743\nEpoch 13/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1328.9999 - mse: 1328.9999 - val_loss: 620.0811 - val_mse: 620.0811\nEpoch 14/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1189.7056 - mse: 1189.7056 - val_loss: 618.1779 - val_mse: 618.1779\nEpoch 15/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1096.0687 - mse: 1096.0687 - val_loss: 670.3808 - val_mse: 670.3808\nEpoch 16/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1027.6211 - mse: 1027.6211 - val_loss: 622.1691 - val_mse: 622.1691\nEpoch 17/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 971.7148 - mse: 971.7148 - val_loss: 617.1715 - val_mse: 617.1715\nEpoch 18/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 900.4524 - mse: 900.4524 - val_loss: 636.3351 - val_mse: 636.3351\nEpoch 19/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 925.7706 - mse: 925.7706 - val_loss: 735.0362 - val_mse: 735.0362\nEpoch 20/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 926.7844 - mse: 926.7844 - val_loss: 620.6200 - val_mse: 620.6200\nEpoch 21/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 885.9457 - mse: 885.9457 - val_loss: 649.6333 - val_mse: 649.6333\nEpoch 22/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 909.2552 - mse: 909.2552 - val_loss: 626.9734 - val_mse: 626.9734\nEpoch 23/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 907.0679 - mse: 907.0679 - val_loss: 627.3849 - val_mse: 627.3849\nEpoch 24/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 878.8497 - mse: 878.8497 - val_loss: 637.9811 - val_mse: 637.9811\nEpoch 25/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 903.8107 - mse: 903.8107 - val_loss: 679.6400 - val_mse: 679.6400\nEpoch 26/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 889.5860 - mse: 889.5860 - val_loss: 617.1707 - val_mse: 617.1707\nEpoch 27/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 892.0016 - mse: 892.0016 - val_loss: 629.0040 - val_mse: 629.0040\nEpoch 28/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 868.4390 - mse: 868.4390 - val_loss: 617.1982 - val_mse: 617.1982\nEpoch 29/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 879.0714 - mse: 879.0714 - val_loss: 617.1498 - val_mse: 617.1498\nEpoch 30/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 878.5392 - mse: 878.5392 - val_loss: 638.9778 - val_mse: 638.9778\nEpoch 31/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 882.8369 - mse: 882.8369 - val_loss: 655.2939 - val_mse: 655.2939\nEpoch 32/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 878.7997 - mse: 878.7997 - val_loss: 472.1201 - val_mse: 472.1201\nEpoch 33/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 695.2987 - mse: 695.2987 - val_loss: 262.6179 - val_mse: 262.6179\nEpoch 34/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 506.3013 - mse: 506.3013 - val_loss: 216.6983 - val_mse: 216.6983\nEpoch 35/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 444.8990 - mse: 444.8990 - val_loss: 206.1570 - val_mse: 206.1570\nEpoch 36/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 453.1880 - mse: 453.1880 - val_loss: 206.7629 - val_mse: 206.7629\nEpoch 37/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 425.4643 - mse: 425.4643 - val_loss: 202.7637 - val_mse: 202.7637\nEpoch 38/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 420.2372 - mse: 420.2372 - val_loss: 195.9906 - val_mse: 195.9906\nEpoch 39/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 422.6107 - mse: 422.6107 - val_loss: 196.3728 - val_mse: 196.3728\nEpoch 40/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 413.2051 - mse: 413.2051 - val_loss: 198.2506 - val_mse: 198.2506\nEpoch 41/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 409.2017 - mse: 409.2017 - val_loss: 208.1166 - val_mse: 208.1166\nEpoch 42/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 416.8824 - mse: 416.8824 - val_loss: 195.3821 - val_mse: 195.3821\nEpoch 43/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 402.1500 - mse: 402.1500 - val_loss: 192.2731 - val_mse: 192.2731\nEpoch 44/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 407.6841 - mse: 407.6841 - val_loss: 190.6191 - val_mse: 190.6191\nEpoch 45/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 403.6703 - mse: 403.6703 - val_loss: 189.3366 - val_mse: 189.3366\nEpoch 46/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 396.5925 - mse: 396.5925 - val_loss: 188.9515 - val_mse: 188.9515\nEpoch 47/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 395.8748 - mse: 395.8748 - val_loss: 187.0933 - val_mse: 187.0933\nEpoch 48/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 393.4927 - mse: 393.4927 - val_loss: 183.1177 - val_mse: 183.1177\nEpoch 49/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 386.9028 - mse: 386.9028 - val_loss: 186.5422 - val_mse: 186.5422\nEpoch 50/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 377.7702 - mse: 377.7702 - val_loss: 193.9399 - val_mse: 193.9399\nEpoch 51/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 390.5818 - mse: 390.5818 - val_loss: 189.5692 - val_mse: 189.5692\nEpoch 52/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 377.4873 - mse: 377.4873 - val_loss: 182.4523 - val_mse: 182.4523\nEpoch 53/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 376.6747 - mse: 376.6747 - val_loss: 186.2833 - val_mse: 186.2833\nEpoch 54/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 378.7720 - mse: 378.7720 - val_loss: 184.2761 - val_mse: 184.2761\nEpoch 55/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 386.4992 - mse: 386.4992 - val_loss: 187.4497 - val_mse: 187.4497\nEpoch 56/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 369.9644 - mse: 369.9644 - val_loss: 203.1587 - val_mse: 203.1587\nEpoch 57/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 370.2960 - mse: 370.2960 - val_loss: 191.5704 - val_mse: 191.5704\nEpoch 58/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 369.6502 - mse: 369.6502 - val_loss: 191.2390 - val_mse: 191.2390\nEpoch 59/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 363.8866 - mse: 363.8866 - val_loss: 186.9446 - val_mse: 186.9446\nEpoch 60/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 376.5647 - mse: 376.5647 - val_loss: 189.7598 - val_mse: 189.7598\nEpoch 61/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 372.1916 - mse: 372.1916 - val_loss: 193.4518 - val_mse: 193.4518\nEpoch 62/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 363.3285 - mse: 363.3285 - val_loss: 182.9499 - val_mse: 182.9499\nEpoch 63/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 359.0821 - mse: 359.0821 - val_loss: 193.3405 - val_mse: 193.3405\nEpoch 64/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 361.1774 - mse: 361.1774 - val_loss: 188.8311 - val_mse: 188.8311\nEpoch 65/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 360.7387 - mse: 360.7387 - val_loss: 219.5405 - val_mse: 219.5405\nEpoch 66/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 350.1152 - mse: 350.1152 - val_loss: 197.4453 - val_mse: 197.4453\nEpoch 67/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 345.8777 - mse: 345.8777 - val_loss: 212.3443 - val_mse: 212.3443\nEpoch 68/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 347.5600 - mse: 347.5600 - val_loss: 197.4764 - val_mse: 197.4764\nEpoch 69/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 348.9524 - mse: 348.9524 - val_loss: 214.5836 - val_mse: 214.5836\nEpoch 70/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 342.2246 - mse: 342.2246 - val_loss: 192.2540 - val_mse: 192.2540\nEpoch 71/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 343.8337 - mse: 343.8337 - val_loss: 204.0940 - val_mse: 204.0940\nEpoch 72/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 337.6600 - mse: 337.6600 - val_loss: 189.1301 - val_mse: 189.1301\nEpoch 73/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 335.3217 - mse: 335.3217 - val_loss: 189.7357 - val_mse: 189.7357\nEpoch 74/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 330.7076 - mse: 330.7076 - val_loss: 197.1943 - val_mse: 197.1943\nEpoch 75/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 332.9995 - mse: 332.9995 - val_loss: 197.0110 - val_mse: 197.0110\nEpoch 76/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 331.6945 - mse: 331.6945 - val_loss: 206.9246 - val_mse: 206.9246\nEpoch 77/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 332.7509 - mse: 332.7509 - val_loss: 200.4073 - val_mse: 200.4073\nEpoch 78/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 333.7151 - mse: 333.7151 - val_loss: 195.6636 - val_mse: 195.6636\nEpoch 79/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 330.5441 - mse: 330.5441 - val_loss: 203.4729 - val_mse: 203.4729\nEpoch 80/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 328.9959 - mse: 328.9959 - val_loss: 203.5381 - val_mse: 203.5381\nEpoch 81/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 320.9268 - mse: 320.9268 - val_loss: 212.4855 - val_mse: 212.4855\nEpoch 82/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 327.4047 - mse: 327.4047 - val_loss: 197.1737 - val_mse: 197.1737\nEpoch 83/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 329.0932 - mse: 329.0932 - val_loss: 197.9148 - val_mse: 197.9148\nEpoch 84/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 322.5079 - mse: 322.5079 - val_loss: 195.1676 - val_mse: 195.1676\nEpoch 85/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 319.3441 - mse: 319.3441 - val_loss: 201.2743 - val_mse: 201.2743\nEpoch 86/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 321.6371 - mse: 321.6371 - val_loss: 199.2340 - val_mse: 199.2340\nEpoch 87/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 308.8088 - mse: 308.8088 - val_loss: 202.3384 - val_mse: 202.3384\nEpoch 88/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 315.1227 - mse: 315.1227 - val_loss: 193.3298 - val_mse: 193.3298\nEpoch 89/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 312.1050 - mse: 312.1050 - val_loss: 199.0648 - val_mse: 199.0648\nEpoch 90/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 316.8701 - mse: 316.8701 - val_loss: 194.7643 - val_mse: 194.7643\nEpoch 91/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 308.5815 - mse: 308.5815 - val_loss: 213.2077 - val_mse: 213.2077\nEpoch 92/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 311.1623 - mse: 311.1623 - val_loss: 213.4053 - val_mse: 213.4053\nEpoch 93/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 307.1967 - mse: 307.1967 - val_loss: 204.6856 - val_mse: 204.6856\nEpoch 94/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 313.0553 - mse: 313.0553 - val_loss: 203.6701 - val_mse: 203.6701\nEpoch 95/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 315.9273 - mse: 315.9273 - val_loss: 207.3466 - val_mse: 207.3466\nEpoch 96/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 308.3243 - mse: 308.3243 - val_loss: 214.1356 - val_mse: 214.1356\nEpoch 97/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 306.5255 - mse: 306.5255 - val_loss: 217.4269 - val_mse: 217.4269\nEpoch 98/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 310.3385 - mse: 310.3385 - val_loss: 221.3301 - val_mse: 221.3301\nEpoch 99/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 304.4685 - mse: 304.4685 - val_loss: 201.9572 - val_mse: 201.9572\nEpoch 100/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 307.6503 - mse: 307.6503 - val_loss: 198.3576 - val_mse: 198.3576\nEpoch 101/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 294.4065 - mse: 294.4065 - val_loss: 203.1812 - val_mse: 203.1812\nEpoch 102/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 302.1014 - mse: 302.1014 - val_loss: 200.8956 - val_mse: 200.8956\nEpoch 103/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 298.4506 - mse: 298.4506 - val_loss: 200.9645 - val_mse: 200.9645\nEpoch 104/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 297.4669 - mse: 297.4669 - val_loss: 203.4427 - val_mse: 203.4427\nEpoch 105/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 299.5648 - mse: 299.5648 - val_loss: 200.8626 - val_mse: 200.8626\nEpoch 106/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 291.3008 - mse: 291.3008 - val_loss: 199.5347 - val_mse: 199.5347\nEpoch 107/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 299.4949 - mse: 299.4949 - val_loss: 211.5331 - val_mse: 211.5331\nEpoch 108/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 290.9811 - mse: 290.9811 - val_loss: 199.4517 - val_mse: 199.4517\nEpoch 109/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 297.7151 - mse: 297.7151 - val_loss: 205.4326 - val_mse: 205.4326\nEpoch 110/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 293.2379 - mse: 293.2379 - val_loss: 206.4093 - val_mse: 206.4093\nEpoch 111/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 293.3941 - mse: 293.3941 - val_loss: 205.5542 - val_mse: 205.5542\nEpoch 112/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 295.4824 - mse: 295.4824 - val_loss: 203.4960 - val_mse: 203.4960\nEpoch 113/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 290.5067 - mse: 290.5067 - val_loss: 201.3253 - val_mse: 201.3253\nEpoch 114/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 290.9166 - mse: 290.9166 - val_loss: 204.5708 - val_mse: 204.5708\nEpoch 115/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 291.4950 - mse: 291.4950 - val_loss: 208.0760 - val_mse: 208.0760\nEpoch 116/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 291.8891 - mse: 291.8891 - val_loss: 209.7970 - val_mse: 209.7970\nEpoch 117/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 280.6028 - mse: 280.6028 - val_loss: 210.1290 - val_mse: 210.1290\nEpoch 118/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 283.9775 - mse: 283.9775 - val_loss: 205.2074 - val_mse: 205.2074\nEpoch 119/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 288.3879 - mse: 288.3879 - val_loss: 204.0640 - val_mse: 204.0640\nEpoch 120/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 291.0957 - mse: 291.0957 - val_loss: 216.8313 - val_mse: 216.8313\nEpoch 121/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 286.1643 - mse: 286.1643 - val_loss: 213.7966 - val_mse: 213.7966\nEpoch 122/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 282.3502 - mse: 282.3502 - val_loss: 203.1225 - val_mse: 203.1225\nEpoch 123/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 286.0198 - mse: 286.0198 - val_loss: 216.3314 - val_mse: 216.3314\nEpoch 124/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 285.0611 - mse: 285.0611 - val_loss: 212.6730 - val_mse: 212.6730\nEpoch 125/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 268.5040 - mse: 268.5040 - val_loss: 219.2832 - val_mse: 219.2832\nEpoch 126/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 285.3501 - mse: 285.3501 - val_loss: 208.8276 - val_mse: 208.8276\nEpoch 127/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 280.9439 - mse: 280.9439 - val_loss: 207.2928 - val_mse: 207.2928\nEpoch 128/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 281.5087 - mse: 281.5087 - val_loss: 209.0065 - val_mse: 209.0065\nEpoch 129/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 276.0318 - mse: 276.0318 - val_loss: 201.5202 - val_mse: 201.5202\nEpoch 130/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 276.2820 - mse: 276.2820 - val_loss: 212.0036 - val_mse: 212.0036\nEpoch 131/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 273.9963 - mse: 273.9963 - val_loss: 208.4543 - val_mse: 208.4543\nEpoch 132/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 275.8350 - mse: 275.8350 - val_loss: 206.0108 - val_mse: 206.0108\nEpoch 133/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 271.2775 - mse: 271.2775 - val_loss: 209.8391 - val_mse: 209.8391\nEpoch 134/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 277.0880 - mse: 277.0880 - val_loss: 212.5663 - val_mse: 212.5663\nEpoch 135/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 269.4303 - mse: 269.4303 - val_loss: 209.0219 - val_mse: 209.0219\nEpoch 136/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 278.2074 - mse: 278.2074 - val_loss: 207.1349 - val_mse: 207.1349\nEpoch 137/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 279.5897 - mse: 279.5897 - val_loss: 206.9595 - val_mse: 206.9595\nEpoch 138/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 272.3693 - mse: 272.3693 - val_loss: 209.3359 - val_mse: 209.3359\nEpoch 139/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 267.9329 - mse: 267.9329 - val_loss: 206.0874 - val_mse: 206.0874\nEpoch 140/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 268.7910 - mse: 268.7910 - val_loss: 212.7362 - val_mse: 212.7362\nEpoch 141/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 272.5075 - mse: 272.5075 - val_loss: 203.0282 - val_mse: 203.0282\nEpoch 142/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 262.4504 - mse: 262.4504 - val_loss: 210.2717 - val_mse: 210.2717\nEpoch 143/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 269.0473 - mse: 269.0473 - val_loss: 212.7621 - val_mse: 212.7621\nEpoch 144/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 274.2495 - mse: 274.2495 - val_loss: 206.3532 - val_mse: 206.3532\nEpoch 145/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 265.6225 - mse: 265.6225 - val_loss: 210.1077 - val_mse: 210.1077\nEpoch 146/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 268.4269 - mse: 268.4269 - val_loss: 204.9657 - val_mse: 204.9657\nEpoch 147/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 264.2469 - mse: 264.2469 - val_loss: 211.9762 - val_mse: 211.9762\nEpoch 148/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 273.3979 - mse: 273.3979 - val_loss: 208.2678 - val_mse: 208.2678\nEpoch 149/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 268.3419 - mse: 268.3419 - val_loss: 207.7386 - val_mse: 207.7386\nEpoch 150/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 268.0630 - mse: 268.0630 - val_loss: 204.3401 - val_mse: 204.3401\nEpoch 151/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 267.9908 - mse: 267.9908 - val_loss: 207.9131 - val_mse: 207.9131\nEpoch 152/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 267.9914 - mse: 267.9914 - val_loss: 218.2114 - val_mse: 218.2114\nEpoch 153/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 267.2340 - mse: 267.2340 - val_loss: 205.4145 - val_mse: 205.4145\nEpoch 154/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 258.3597 - mse: 258.3597 - val_loss: 203.5338 - val_mse: 203.5338\nEpoch 155/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 264.5133 - mse: 264.5133 - val_loss: 206.4163 - val_mse: 206.4163\nEpoch 156/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 260.5875 - mse: 260.5875 - val_loss: 206.2991 - val_mse: 206.2991\nEpoch 157/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 262.4985 - mse: 262.4985 - val_loss: 209.8763 - val_mse: 209.8763\nEpoch 158/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 260.7858 - mse: 260.7858 - val_loss: 200.7218 - val_mse: 200.7218\nEpoch 159/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 264.9231 - mse: 264.9231 - val_loss: 207.1140 - val_mse: 207.1140\nEpoch 160/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 257.9016 - mse: 257.9016 - val_loss: 206.8936 - val_mse: 206.8936\nEpoch 161/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 254.9479 - mse: 254.9479 - val_loss: 209.5208 - val_mse: 209.5208\nEpoch 162/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 262.4875 - mse: 262.4875 - val_loss: 206.9213 - val_mse: 206.9213\nEpoch 163/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 258.1866 - mse: 258.1866 - val_loss: 206.5526 - val_mse: 206.5526\nEpoch 164/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 252.9555 - mse: 252.9555 - val_loss: 204.9631 - val_mse: 204.9631\nEpoch 165/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 257.8389 - mse: 257.8389 - val_loss: 207.9131 - val_mse: 207.9131\nEpoch 166/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 252.9496 - mse: 252.9496 - val_loss: 210.5759 - val_mse: 210.5759\nEpoch 167/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 254.5889 - mse: 254.5889 - val_loss: 202.2354 - val_mse: 202.2354\nEpoch 168/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 255.9455 - mse: 255.9455 - val_loss: 202.5488 - val_mse: 202.5488\nEpoch 169/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 255.8746 - mse: 255.8746 - val_loss: 208.8239 - val_mse: 208.8239\nEpoch 170/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 252.7597 - mse: 252.7597 - val_loss: 203.2300 - val_mse: 203.2300\nEpoch 171/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 254.8540 - mse: 254.8540 - val_loss: 210.9920 - val_mse: 210.9920\nEpoch 172/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 248.3952 - mse: 248.3952 - val_loss: 211.6991 - val_mse: 211.6991\nEpoch 173/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 254.8678 - mse: 254.8678 - val_loss: 206.6005 - val_mse: 206.6005\nEpoch 174/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 261.5232 - mse: 261.5232 - val_loss: 209.0919 - val_mse: 209.0919\nEpoch 175/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 253.9369 - mse: 253.9369 - val_loss: 213.3573 - val_mse: 213.3573\nEpoch 176/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 250.0854 - mse: 250.0854 - val_loss: 212.5963 - val_mse: 212.5963\nEpoch 177/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 254.7582 - mse: 254.7582 - val_loss: 221.0171 - val_mse: 221.0171\nEpoch 178/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 256.3898 - mse: 256.3898 - val_loss: 210.1901 - val_mse: 210.1901\nEpoch 179/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 244.2224 - mse: 244.2224 - val_loss: 215.1480 - val_mse: 215.1480\nEpoch 180/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 252.7020 - mse: 252.7020 - val_loss: 221.9818 - val_mse: 221.9818\nEpoch 181/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 251.4568 - mse: 251.4568 - val_loss: 216.0561 - val_mse: 216.0561\nEpoch 182/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 250.5679 - mse: 250.5679 - val_loss: 214.5278 - val_mse: 214.5278\nEpoch 183/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 243.7072 - mse: 243.7072 - val_loss: 208.1293 - val_mse: 208.1293\nEpoch 184/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 251.0739 - mse: 251.0739 - val_loss: 214.7869 - val_mse: 214.7869\nEpoch 185/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 247.2633 - mse: 247.2633 - val_loss: 205.4252 - val_mse: 205.4252\nEpoch 186/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 246.7146 - mse: 246.7146 - val_loss: 209.4719 - val_mse: 209.4719\nEpoch 187/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 246.2933 - mse: 246.2933 - val_loss: 222.1221 - val_mse: 222.1221\nEpoch 188/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 245.0282 - mse: 245.0282 - val_loss: 209.8623 - val_mse: 209.8623\nEpoch 189/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 242.4205 - mse: 242.4205 - val_loss: 213.6788 - val_mse: 213.6788\nEpoch 190/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 246.9030 - mse: 246.9030 - val_loss: 213.4118 - val_mse: 213.4118\nEpoch 191/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 247.8955 - mse: 247.8955 - val_loss: 215.0171 - val_mse: 215.0171\nEpoch 192/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 243.4247 - mse: 243.4247 - val_loss: 213.0818 - val_mse: 213.0818\nEpoch 193/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 243.8895 - mse: 243.8895 - val_loss: 219.7370 - val_mse: 219.7370\nEpoch 194/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 244.3290 - mse: 244.3290 - val_loss: 210.9647 - val_mse: 210.9647\nEpoch 195/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 240.1634 - mse: 240.1634 - val_loss: 222.7197 - val_mse: 222.7197\nEpoch 196/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 240.7428 - mse: 240.7428 - val_loss: 210.9816 - val_mse: 210.9816\nEpoch 197/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 241.4110 - mse: 241.4110 - val_loss: 216.0297 - val_mse: 216.0297\nEpoch 198/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 239.5910 - mse: 239.5910 - val_loss: 211.5568 - val_mse: 211.5568\nEpoch 199/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 234.5328 - mse: 234.5328 - val_loss: 210.2685 - val_mse: 210.2685\nEpoch 200/200\n\u001b[1m259/259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 239.2380 - mse: 239.2380 - val_loss: 216.2351 - val_mse: 216.2351\nCPU times: user 6min 13s, sys: 47.2 s, total: 7min\nWall time: 4min 17s\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"y_pred = model.predict(x_test)\nmodel_r2 = r2_score(y_test, y_pred)\nmodel_mae = mean_absolute_error(y_test, y_pred)\nmodel_mse = mean_squared_error(y_test, y_pred)\nprint(model_r2, model_mae, model_mse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:36:27.761637Z","iopub.execute_input":"2024-12-12T15:36:27.762312Z","iopub.status.idle":"2024-12-12T15:36:28.279845Z","shell.execute_reply.started":"2024-12-12T15:36:27.762275Z","shell.execute_reply":"2024-12-12T15:36:28.278961Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n0.6402776111300605 10.51220337166219 219.08354437431342\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def build_model(hp):\n    model = Sequential()\n    model.add(Embedding(output_dim=50, input_dim=21, input_length=10))\n\n    model.add(GRU(hp.Int('units_1', min_value=32, max_value=128, step=32),\n                  return_sequences=True, input_shape=(10, 21)))\n    model.add(Dropout(hp.Float('dropout_1', min_value=0.0, max_value=0.8)))\n\n    model.add(GRU(hp.Int('units_2', min_value=32, max_value=128, step=32)))\n    model.add(Dropout(hp.Float('dropout_2', min_value=0.0, max_value=0.8)))\n\n    model.add(Dense(1))\n\n    learning_rate = hp.Choice('learning_rate', values=[0.001, 0.005])\n    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n\n    model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n\n    return model\n\ntuner = RandomSearch(\n    build_model,\n    objective='val_mse',\n    max_trials=10,  \n    executions_per_trial=1,  \n    directory='tuner_results',\n    project_name='gru_model_tuning_9'\n)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\ntuner.search(x_train, y_train,\n             epochs=200,\n             batch_size=tuner.oracle.hyperparameters.Choice('batch_size', values=[64, 128, 256, 512]),\n             validation_data=(x_val, y_val),\n             callbacks=[early_stopping],\n             verbose=1)\n\nbest_model = tuner.get_best_models(num_models=1)[0]\nbest_run = tuner.oracle.get_best_trials(num_trials=1)[0]\n\nbest_model.summary()\nprint(best_run.hyperparameters.values)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:12:33.348070Z","iopub.execute_input":"2024-12-07T15:12:33.348464Z","iopub.status.idle":"2024-12-07T15:44:54.136396Z","shell.execute_reply.started":"2024-12-07T15:12:33.348431Z","shell.execute_reply":"2024-12-07T15:44:54.135646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\n#model GRU\nmodel1 = Sequential()\nmodel1.add(Embedding(output_dim = 50, input_dim = 21, input_length = 10))\n\nmodel1.add(GRU(128, return_sequences=True))\nmodel1.add(Dropout(0.76))\n\nmodel1.add(GRU(96))\nmodel1.add(Dropout(0.05))\n\nmodel1.add(Dense(1))\n\noptimizer = tf.keras.optimizers.Adam(0.001)\n\nmodel1.compile(loss='mse', optimizer=optimizer)\nmodel1.fit(x_train, y_train, \n           epochs = 100, \n           batch_size = 64, \n           validation_data = (x_val, y_val))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:48:08.968220Z","iopub.execute_input":"2024-12-12T15:48:08.968589Z","iopub.status.idle":"2024-12-12T15:52:55.480846Z","shell.execute_reply.started":"2024-12-12T15:48:08.968556Z","shell.execute_reply":"2024-12-12T15:52:55.479920Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"Argument `input_length` is deprecated. Just remove it.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 108103.7266 - val_loss: 84099.4922\nEpoch 2/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 77421.7344 - val_loss: 59907.8750\nEpoch 3/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 54784.3320 - val_loss: 41237.5547\nEpoch 4/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 37448.6250 - val_loss: 27155.4297\nEpoch 5/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 24264.0664 - val_loss: 16899.8203\nEpoch 6/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 14966.3604 - val_loss: 9816.5117\nEpoch 7/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 8510.9971 - val_loss: 5268.4810\nEpoch 8/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 4534.7163 - val_loss: 2644.5688\nEpoch 9/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 2287.7913 - val_loss: 1339.5229\nEpoch 10/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 1222.2279 - val_loss: 814.5157\nEpoch 11/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 855.2708 - val_loss: 655.5408\nEpoch 12/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 710.3012 - val_loss: 622.4478\nEpoch 13/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 694.6500 - val_loss: 617.8809\nEpoch 14/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 705.2848 - val_loss: 617.3616\nEpoch 15/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 703.5734 - val_loss: 617.3865\nEpoch 16/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 718.1495 - val_loss: 617.4131\nEpoch 17/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 695.4410 - val_loss: 617.2673\nEpoch 18/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 711.4625 - val_loss: 617.2839\nEpoch 19/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 712.9993 - val_loss: 617.2624\nEpoch 20/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 705.9170 - val_loss: 617.4719\nEpoch 21/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 699.6414 - val_loss: 617.7744\nEpoch 22/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 692.2264 - val_loss: 617.6550\nEpoch 23/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 710.7899 - val_loss: 617.3264\nEpoch 24/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 724.8220 - val_loss: 617.6163\nEpoch 25/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 567.7051 - val_loss: 234.0437\nEpoch 26/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 329.0443 - val_loss: 214.1972\nEpoch 27/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 311.1885 - val_loss: 208.1631\nEpoch 28/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 303.4778 - val_loss: 200.9792\nEpoch 29/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 298.4892 - val_loss: 209.9566\nEpoch 30/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 298.0303 - val_loss: 195.5916\nEpoch 31/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 300.0711 - val_loss: 197.5693\nEpoch 32/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 300.3669 - val_loss: 199.2240\nEpoch 33/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 284.9669 - val_loss: 209.0441\nEpoch 34/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 283.5445 - val_loss: 194.6022\nEpoch 35/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 286.2268 - val_loss: 188.7209\nEpoch 36/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 279.1781 - val_loss: 191.0115\nEpoch 37/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 277.9717 - val_loss: 190.4104\nEpoch 38/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 273.4981 - val_loss: 187.1538\nEpoch 39/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 277.0253 - val_loss: 183.2633\nEpoch 40/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 269.8511 - val_loss: 185.6473\nEpoch 41/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 273.6407 - val_loss: 190.3479\nEpoch 42/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 273.4227 - val_loss: 181.7467\nEpoch 43/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 269.1577 - val_loss: 184.4286\nEpoch 44/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 274.7521 - val_loss: 193.1025\nEpoch 45/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 268.3764 - val_loss: 178.3089\nEpoch 46/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 266.2988 - val_loss: 176.8096\nEpoch 47/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 269.8353 - val_loss: 181.2072\nEpoch 48/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 263.8286 - val_loss: 183.7143\nEpoch 49/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 261.8358 - val_loss: 173.3063\nEpoch 50/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 262.0253 - val_loss: 175.9171\nEpoch 51/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 262.8615 - val_loss: 180.4066\nEpoch 52/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 258.5753 - val_loss: 179.5025\nEpoch 53/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 258.5019 - val_loss: 180.2760\nEpoch 54/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 256.9024 - val_loss: 173.8610\nEpoch 55/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 259.0963 - val_loss: 173.5957\nEpoch 56/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 259.9812 - val_loss: 184.9917\nEpoch 57/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 256.8890 - val_loss: 183.2916\nEpoch 58/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 253.1337 - val_loss: 180.9133\nEpoch 59/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 250.8239 - val_loss: 172.2633\nEpoch 60/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 246.7189 - val_loss: 182.9430\nEpoch 61/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 244.4632 - val_loss: 177.6189\nEpoch 62/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 240.4613 - val_loss: 174.5743\nEpoch 63/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 243.4007 - val_loss: 170.2592\nEpoch 64/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 237.1490 - val_loss: 178.4924\nEpoch 65/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 239.7301 - val_loss: 191.2594\nEpoch 66/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 234.5501 - val_loss: 180.4432\nEpoch 67/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 234.6040 - val_loss: 189.0711\nEpoch 68/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 236.8844 - val_loss: 180.6445\nEpoch 69/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 232.4345 - val_loss: 195.5045\nEpoch 70/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 230.3094 - val_loss: 193.7180\nEpoch 71/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 232.1188 - val_loss: 184.8278\nEpoch 72/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 230.0152 - val_loss: 183.8862\nEpoch 73/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 222.7123 - val_loss: 185.0942\nEpoch 74/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 222.5466 - val_loss: 181.8385\nEpoch 75/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 224.6585 - val_loss: 204.5433\nEpoch 76/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 218.1106 - val_loss: 181.8510\nEpoch 77/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 227.1097 - val_loss: 195.7303\nEpoch 78/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 215.2349 - val_loss: 184.6245\nEpoch 79/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 219.5645 - val_loss: 180.4892\nEpoch 80/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 214.0610 - val_loss: 187.8243\nEpoch 81/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 212.7338 - val_loss: 191.7266\nEpoch 82/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 215.5863 - val_loss: 188.0705\nEpoch 83/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 211.4869 - val_loss: 201.0533\nEpoch 84/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 211.4250 - val_loss: 193.2858\nEpoch 85/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 207.8381 - val_loss: 192.6494\nEpoch 86/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 209.4759 - val_loss: 185.3037\nEpoch 87/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 206.0987 - val_loss: 186.4995\nEpoch 88/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 202.6597 - val_loss: 184.8279\nEpoch 89/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 200.9041 - val_loss: 192.5175\nEpoch 90/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 206.4870 - val_loss: 204.4189\nEpoch 91/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 204.4726 - val_loss: 206.0037\nEpoch 92/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 202.8964 - val_loss: 195.7066\nEpoch 93/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 202.7377 - val_loss: 185.3007\nEpoch 94/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 198.7075 - val_loss: 185.0499\nEpoch 95/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 202.1764 - val_loss: 193.1154\nEpoch 96/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 198.8360 - val_loss: 184.0196\nEpoch 97/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 193.6212 - val_loss: 187.4238\nEpoch 98/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 200.0346 - val_loss: 190.6752\nEpoch 99/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 195.4888 - val_loss: 188.0263\nEpoch 100/100\n\u001b[1m518/518\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 198.4124 - val_loss: 184.6196\nCPU times: user 6min 42s, sys: 42.5 s, total: 7min 25s\nWall time: 4min 46s\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x79bdd441b2b0>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"y_pred1 = model1.predict(x_test)\nmodel1_r2 = r2_score(y_test, y_pred1)\nmodel1_mae = mean_absolute_error(y_test, y_pred1)\nmodel1_mse = mean_squared_error(y_test, y_pred1)\nprint(model1_r2, model1_mae, model1_mse)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T15:53:12.702576Z","iopub.execute_input":"2024-12-12T15:53:12.702923Z","iopub.status.idle":"2024-12-12T15:53:13.321542Z","shell.execute_reply.started":"2024-12-12T15:53:12.702891Z","shell.execute_reply":"2024-12-12T15:53:13.320800Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n0.6921918400980549 9.608411211219915 187.46595915395045\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"#Chọn model\nmodel = model1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**SHAP**","metadata":{}},{"cell_type":"code","source":"%%time\n\n#Tạo 100 cụm dữ liệu để tính toán SHAP\nx_trainmeans = shap.kmeans(np.asarray(x_train), 100)\nexplainer = shap.KernelExplainer(model.predict, x_trainmeans)\nshap_values = explainer.shap_values(np.asarray(x_test))\n\n#lưu giá trị SHAP\nwith open(\"CCS_shapvalues_GRU.pkl\",\"wb\") as f:\n    pickle.dump(shap_values, f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"/kaggle/input/ccs-position-data/shapvaluesCCS (1).pkl\",\"rb\") as f:\n    shap_values = pickle.load(f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**LIME**","metadata":{}},{"cell_type":"code","source":"%%time\n\n#Định nghĩa hàm giải thích LIME\nexplainer = lime.lime_tabular.LimeTabularExplainer(\n    training_data = x_train,\n    mode = 'regression',\n    feature_names = [f'Pos{i+1}' for i in range(10)],\n)\npositions = [f'Pos{i+1}' for i in range(10)]\n\nlime_values = []\nfor i in range(len(x_test)):\n    x_instance = x_test[i]\n    ordered_contributions = {pos: 0.0 for pos in positions}\n\n    #Tính LIME cho từng instance\n    exp = explainer.explain_instance(\n        data_row = x_instance,\n        predict_fn = model.predict\n    )\n\n    for feature_value, contribution in exp.as_list():\n        pos = next((word for word in feature_value.split() if word.startswith('Pos')), None)\n        if pos in ordered_contributions:\n            ordered_contributions[pos] += contribution\n\n    contributions_sorted = [ordered_contributions[pos] for pos in positions]\n    lime_values.append(contributions_sorted)\n\nwith open('CCS_lime_values_LSTM.pkl', 'wb') as f:\n    pickle.dump(lime_values, f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('/kaggle/input/ccs-position-data/CCS_lime_values_LSTM.pkl', 'rb') as f:\n    lime_values = pickle.load(f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**OSA**","metadata":{}},{"cell_type":"code","source":"%%time\n\n#Tính OSA\nbaseline = 0\noriginal_output = model.predict(x_test).flatten()\nosa_values = np.zeros_like(x_test, dtype=np.float32)\n\nfor i in range(10)):\n    osa_inputs = x_test.copy()\n    osa_inputs[:,i] = baseline\n    osa_output = model.predict(osa_inputs).flatten()\n\n    osa_values[:,i] = np.abs(original_output - osa_output)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**HEATMAP**","metadata":{}},{"cell_type":"code","source":"#Tạo mange lưu các giá trị SHAP/LIME/OSA của 1 axit amin ở cùng 1 vị trí (pos=[1,10])\n\n#Chọn giá trị\nexplain_values = shap_values\n\naa = []\ni = 0\nwhile i < 10:\n    aa.append([[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0]])\n    i+=1\n\ni=0\nwhile i < len(x_test):\n    j = 0\n    while j < len(x_test[i]):\n        aa[j][int(x_test[i][j])].append(explain_values[0][i][j])\n        j+=1\n    i+=1\n\nheatmap = []\n\ni = 0\nwhile i < len(aa):\n    j = 0\n    heatmap.append([])\n    while j < len(aa[i]):\n        if len(aa[i][j]) > 1:\n            aa[i][j] = aa[i][j][1:]\n            heatmap[i].append(sum(aa[i][j])/float(len(aa[i][j])))\n        else:\n            heatmap[i].append(0)\n        j+=1\n    i+=1\nheatmap = np.array(heatmap)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure()\nx_axis_labels = ['A','C','D','E','End','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y'] # labels for x-axis\ny_axis_labels = ['1','2','3','4','5','6','7','8','9','10']\nsns.set(font_scale = 2)\n\nrcParams['figure.figsize'] = 20,16\nax = sns.heatmap(heatmap,xticklabels=x_axis_labels, yticklabels=y_axis_labels,linewidths=.5,  cmap=\"viridis\")\n\nax.set(xlabel='Amino Acid', ylabel='Position', title='Mean SHAP Values - CCS')\nax.figure.savefig('CCS.png')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}